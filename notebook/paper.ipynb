{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98b3ebe5",
   "metadata": {},
   "source": [
    "UDC 519.688\n",
    "\n",
    "# Investigating convergence rate of stochastic finite-difference optimization methods\n",
    "\n",
    "${}$\n",
    "\n",
    "${}$\n",
    "\n",
    "**V. I. Norkin${}^{1}$, A. Y. Kozyriev${}^{1}$**\n",
    "\n",
    "1 - Igor Sikorsky Kyiv Polytechnic Institute, Kyiv, Ukraine (vladimir.norkin@gmail.com)\n",
    "\n",
    "${}$\n",
    "\n",
    "${}$\n",
    "\n",
    "_**Abstract.** Nowadays, stochastic gradient algorithms have become one of the most popular numerical optimization methods due to their efficiency and formulation simplicity. They are used in a variety of areas: from cost reduction problems to deep learning. The common feature of all these problems is to find the optimal values for a set of independent parameters in a mathematical model that can be described by a set of equalities and inequalities. The number of computing resources and time spent to solve the problem, the accuracy of the mathematical model, etc. depends on how effective the chosen gradient descent algorithm is. In practice, stochastic gradient algorithms only show fair results for convex and smooth functions. However, most modern optimization problems do not belong to these classes (for instance, a deep neural network with a ReLU activation function is a non-smooth optimization problem). The article proposes a new modification to the existing stochastic gradient algorithms based on an averaged functions smoothing technique and finite-difference approximations with more robustness to the non-smooth target functions._\n",
    "\n",
    "_**Keywords:** gradient descent methods, optimization theory, unconstrained optimization, nonsmooth problems, stochastic gradient descent methods, adaptive gradient descent methods, finite difference methods._\n",
    "\n",
    "## Introduction\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;Most modern stochastic gradient algorithms have significant problems optimizing functions with multiple minima because they are more likely to converge to the local minimum than the global one. Therefore, the research of adaptive stochastic gradient methods on applied non-convex and multi-extreme optimization problems is relevant, which also considers improving existing optimization methods and proposing modifications. The second problem in applying stochastic gradient methods is the possible functions' non-smoothness and the limitations in the optimization problem. Constrained problems can be reduced to unconditional optimization problems with precise penalty functions, but the problem becomes non-smooth. Gradient methods in non-smooth optimization problems demonstrate a slow convergence rate and low robustness to the local minima.\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;The primary goal of the research is to study the outcomes of replacing stochastic gradients in adaptive gradient methods with their central finite-difference alternatives and other finite-difference approximations of increased order of the local truncation error and accumulated error. To some extent, the finite-difference approximations of the gradients smooth the problem and, therefore, even out the shallow local extremes and reduce the problem's convexity.\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;We conducted experimental studies on classical and adaptive gradient methods to confirm the theoretical conclusions. Studies are based on performed gradient substitutions for finite-difference estimates to avoid \"backpropagation\" when calculating gradients.\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;Aside from the general definition of the optimization problem, we consider it as a smooth problem of stochastic programming (1) [1], which we express in the following equation:\n",
    "\n",
    "$$\n",
    "\\begin{matrix}\n",
    "\\min_{x \\in X} f(x) = \\mathbb{E}F(x, \\xi) = \\int_{\\xi \\in \\Xi} F(x, \\xi) P(d \\xi), X \\subseteq \\mathbb{R}^{n} & (1)\n",
    "\\end{matrix}\n",
    "$$\n",
    "\n",
    "We define the target function $ F(x) $ as a continuous and smooth (differentiable) function, $ x \\in \\mathbb{R} $ - a dependent variable defined on a space $ \\inf_{x \\in X} F(x) > - \\infty $, $ \\xi $ - a random variable modeled by a previously unknown probability distribution $ P(d \\xi) $ on the event space $ \\Xi $. By definition, the investigated function $ f $ is a non-analytical and non-smooth function representing an averaged value of a particular stochastic oracle $ \\tilde{F}(x, \\xi_i) $, which also has an approximated value of the gradient $ \\nabla \\tilde{F}(x, \\xi_i) $. A well-known method for estimating the function $ f $ is modeling by the Monte Carlo method or any other stochastic method with a predetermined number of experiments, where $ \\xi $ is a random variable in the mathematical functional model $ \\tilde{F}(x, \\xi_i) $ and the formula for the gradient $ \\nabla \\tilde{F}(x, \\xi_i) $.\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;The method of gradient descent in the problem of stochastic optimization can also be considered an iterative process:\n",
    "\n",
    "$$\n",
    "\\begin{matrix}\n",
    "x_{i+1} = \\Pi_{X}(x_{i} - \\lambda_{i} H_{i}^{-1} g(x_{i}, M(x_{i}))) & (2)\n",
    "\\end{matrix}\n",
    "$$\n",
    "\n",
    "Here the parameter $ \\lambda_{i} $ is a step of the gradient descent method, $ H_{i} $ - the Hesse matrix approximation for the optimization function at each step of the method $ i $, and $ g(x_{i}, M(x_{i})) $ is an approximation of the gradient $ \\nabla \\tilde{F}(x, \\xi_{i}) $ for a specific sample from the set of measurements $ M(x_{i}) $. Here the projection operator $ \\Pi_{X}(y) $ is given by the formula:\n",
    "\n",
    "$$\n",
    "\\begin{matrix}\n",
    "\\Pi_{X}(y) = \\arg \\inf_{x \\in X} \\{ || y - x || \\} & (3)\n",
    "\\end{matrix}\n",
    "$$\n",
    "\n",
    "Before a detailed analysis of stochastic gradient algorithms, we define the gradient of the function and the gradient descent. The gradient of the function $ F $ in space $ \\mathbb{R}^{n} $ is a column vector of partial derivatives with respect to each variable $ x_1, ..., x_n $ for a certain point $ a \\in \\mathbb{R}^{n} $:\n",
    "\n",
    "$$\n",
    "\\begin{matrix}\n",
    "\\nabla F(a) = \\begin{bmatrix} \\frac{\\partial F(a)}{\\partial x_{1}} \\\\ \\vdots \\\\ \\frac{\\partial F(a)}{\\partial x_{n}} \\\\ \\end{bmatrix} & (4)\n",
    "\\end{matrix}\n",
    "$$\n",
    "\n",
    "The main feature of the gradient is the indication of the direction of the largest increment of the function $ F $ at a given point. The main iteration scheme for gradient descent methods is based on it: by assumption, the point of a minimum of the target function is in the direction opposite to the gradient, i.e. the anti-gradient or $ - \\nabla F $. The iteration scheme of gradient descent methods consists of successive updating of independent parameters of the model $ \\theta_{i} $ by the value of the anti-gradient with a certain constant step $ \\lambda \\in [0, 1] $: $ \\theta_{i+1} = \\theta_{i} - \\lambda \\cdot \\nabla F $.\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;The work of the algorithm continues until one of the set limit conditions is reached:\n",
    " - a finite number of iterations;\n",
    " - by the theorem on the necessary condition for the existence of a minimum: $ || \\nabla F(x_{k}) || \\to 0 $ or in the case of stochastic approximation $ \\mathbb{E} || \\nabla F(x_{k}) || \\to 0 $.\n",
    "\n",
    "In this paper, the value of the gradient is calculated by the finite difference method: the value of the derivative is a result of a decomposing transformation of the function into a Taylor series:\n",
    "\n",
    "$$\n",
    "\\begin{matrix}\n",
    "f(x + h) = \\sum_{i=1}^{\\infty} \\frac{f^{(i)}(x)}{i!} h^i & (5)\n",
    "\\end{matrix}\n",
    "$$\n",
    "\n",
    "Before defining the concept of Taylor series approximation and Taylor's Theorem, let us show the basic properties of a function that is $N$-times differentiable.\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;***Theorem 1 \"General Rolle’s theorem\" [2].*** Given the analytical function $ F: (a, b) \\to \\mathbb{R} $ defined on the segment $ (a, b) $ where $ a, b \\in \\mathbb{R}, a < b $. For any natural number $ n \\in \\mathbb{N} $ function is $ N $-times differentiable on the open segment $ (a, b) $ and derivatives $ F, F', ..., F^{(n-1)} $ of the function are continuous on the closed interval $ [a, b] $. Then, if the condition is satisfied $ F(a) = F'(a) = ... = F^{(n-1)}(a) = F(b) = 0 $, on the defined segment exists an element $ c \\in (a, b) $ that will satisfy the following condition $ F^{n}(c) = 0 $. Let us use the properties from the general theorem of Rolle’s to construct an $ N $-degree polynomial for the function $ F $, satisfying the conditions described above, and formulating the following theorem.\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;***Theorem 2 \"Taylor’s theorem\" [3].*** Given the analytical function $ F: (a, b) \\to \\mathbb{R} $ defined on the segment $ (a, b) $ where $ a, b \\in \\mathbb{R}, a < b $. For any natural number $ n \\in \\mathbb{N} $ function is $ N $-times differentiable on the open segment $ (a, b) $ and derivatives $ F, F', ..., F^{(n - 1)} $ of the function are continuous on the closed interval $ [a, b] $. Then exists an element $ c \\in (a, b) $, that guarantees the existence of a single Taylor’s series decomposition:\n",
    "\n",
    "$$\n",
    "\\begin{matrix}\n",
    "f(b) = \\sum_{k=0}^{n-1}\\frac{f^{(k)}(a)}{k!} (b - a)^{k} + \\frac{f^{(n)}(c)}{n!}(b - a)^{n} & (6)\n",
    "\\end{matrix}\n",
    "$$\n",
    "\n",
    "This theorem can be interpreted otherwise: any analytical $ N $-times differentiable function $ F $ can be “reconstructed” at any point of a $ \\mathbb{R} $ space, if we know the value of the function and value of any order derivatives for a single element $ x_{0} \\in \\mathbb{R} $. The equation of Taylor’s series polynomial can be simplified by discarding unnecessary residual terms that have higher accuracy order than the first order. By substituting the difference between of anchor element $ x_{0} \\in \\mathbb{R} $ and other elements from $ \\mathbb{R} $ space with $ h = x - x_{0} $:\n",
    "\n",
    "$$\n",
    "\\begin{matrix}\n",
    "f(x_{0} + h) = f(x_{0}) + f'(x_{0})h + o(h) & (7)\n",
    "\\end{matrix}\n",
    "$$\n",
    "\n",
    "By replacing the terms of the equation we get the numerical formula of the first-order derivative of the function $ f $:\n",
    "\n",
    "$$\n",
    "\\begin{matrix}\n",
    "f_{x_{0} + 0}'(x_{0}) = \\frac{f(x_{0} + h) - f(x_{0})}{h} + o(h) & (8)\n",
    "\\end{matrix}\n",
    "$$\n",
    "\n",
    "Considering equations (6) and (7) we can get numerical derivative for a negative direction $ f_{x_{0} - 0}'(x_{0}) $ by constructing Taylor’s series with the negative value of the step difference $ h < 0 $:\n",
    "\n",
    "$$\n",
    "\\begin{matrix}\n",
    "f(x_{0} - h) = f(x_{0}) + f'(x_{0})(-h) + o(h) \\implies f_{x_{0} - 0}'(x_{0}) = \\frac{f(x_{0}) - f(x_{0} - h)}{h} + o(h) & (9)\n",
    "\\end{matrix}\n",
    "$$\n",
    "\n",
    "By discarding residual terms after the first term, we get the finite-difference approximation of for the derivative value of $ f $ with the precision order $ O(h) $:\n",
    "\n",
    "$$\n",
    "\\begin{matrix}\n",
    "\\begin{cases}\n",
    "f'(x) = \\frac{f(x + h) - f(x)}{h} - \\frac{h f''(\\xi)}{2} \\\\\n",
    "f'(x) = \\frac{f(x) - f(x - h)}{h} + \\frac{h f''(\\xi)}{2}\n",
    "\\end{cases} & (10)\n",
    "\\end{matrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4637a09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import Callable, Tuple\n",
    "\n",
    "\n",
    "def lgrad(F: Callable[[np.array], np.array], x: np.array, h=0.001) -> np.array:\n",
    "    \"\"\"A finite-difference approximation for left-side gradient $\\nabla F_{-}(x)$ with the precision order $O(h)$.\n",
    "    Args:\n",
    "        F (Callable[[np.array], np.array]): a target function $F(x)$ with a single input argument $x \\in \\mathbb{R}^n$.\n",
    "        x (np.array): an input vector $x \\in \\mathbb{R}^n$, where the derivative is calculated.\n",
    "        h (float, optional): a step of the derivative partitioning grid with the range of $0<h<1$. The lower value, the higher gradient precision. Defaults to 0.001.\n",
    "    Returns:\n",
    "        np.array: a gradient vector approximation $\\nabla F_{-}(x)$.\n",
    "    \"\"\"\n",
    "\n",
    "    n, grad = len(x), np.zeros(x.shape)\n",
    "    \n",
    "    for i in range(n):\n",
    "        vh = h * np.eye(1, n, i).reshape((n, ))\n",
    "        grad[i] = (F(x) - F(x - vh)) / h\n",
    "\n",
    "    return grad\n",
    "\n",
    "\n",
    "def rgrad(F: Callable[[np.array], np.array], x: np.array, h=0.001) -> np.array:\n",
    "    \"\"\"A finite-difference approximation for right-side gradient $\\nabla F_{+}(x)$ with the precision order $O(h)$.\n",
    "    Args:\n",
    "        F (Callable[[np.array], np.array]): a target function $F(x)$ with a single input argument $x \\in \\mathbb{R}^n$.\n",
    "        x (np.array): an input vector $x \\in \\mathbb{R}^n$, where the derivative is calculated.\n",
    "        h (float, optional): a step of the derivative partitioning grid with the range of $0<h<1$. The lower value, the higher gradient precision. Defaults to 0.001.\n",
    "    Returns:\n",
    "        np.array: a gradient vector approximation $\\nabla F_{+}(x)$.\n",
    "    \"\"\"\n",
    "\n",
    "    n, grad = len(x), np.zeros(x.shape)\n",
    "\n",
    "    for i in range(n):\n",
    "        vh = h * np.eye(1, n, i).reshape((n, ))\n",
    "        grad[i] = (F(x + vh) - F(x)) / h\n",
    "\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60596735",
   "metadata": {},
   "source": [
    "Let us experimentally evaluate the accuracy of gradient implementations on the set of test functions:\n",
    "\n",
    " - $ f(x) = x^3 + 2x^2 + 12x + 100 \\implies f'(x) = 3x^2 + 4x + 12, f'(2.0) = 32.0 $\n",
    " - $ F(x, y) = x^2 + xy + y^2 \\implies \\begin{cases} \\frac{\\partial F(x, y)}{\\partial x} = 2x + y, \\frac{\\partial F(2.0, -1.0)}{\\partial x} = 3.0 \\\\ \\frac{\\partial F(x, y)}{\\partial y} = x + 2y, \\frac{\\partial F(2.0, -1.0)}{\\partial y} = 0.0\n",
    " \\end{cases} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae275823",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 1e-6\n",
    "x_onedim = np.array([2.0])\n",
    "x_muldim = np.array([2.0, -1.0])\n",
    "\n",
    "f = lambda x: x ** 3 + 2 * x ** 2 + 12 * x + 100\n",
    "F = lambda x: x[0] ** 2 + x[0] * x[1] + x[1] ** 2\n",
    "\n",
    "np.testing.assert_almost_equal(lgrad(f, x_onedim, h=h), 32.0, decimal=5)\n",
    "np.testing.assert_almost_equal(rgrad(f, x_onedim, h=h), 32.0, decimal=5)\n",
    "\n",
    "np.testing.assert_almost_equal(lgrad(F, x_muldim, h=h), np.array([3.0, 0.0]), decimal=5)\n",
    "np.testing.assert_almost_equal(rgrad(F, x_muldim, h=h), np.array([3.0, 0.0]), decimal=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b32132",
   "metadata": {},
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;The accuracy of the approximation depends on the number of nodes on the numerical partitioning grid, thus the smaller step difference, the higher precision. Using the Runge-Romberg-Richardson algorithm [4] we can achieve an increase in the order of the precision of the partitioning grid up to $ O(h^2) $ without adding extra iterations to the approximation algorithm. The approach is based on empirical estimation of the target function value $ z $ while decreasing the step size $ h $. The estimation is based on the assumption:\n",
    "\n",
    "$$\n",
    "\\begin{matrix}\n",
    "z \\approx \\zeta(h) + O(h^p) & (11)\n",
    "\\end{matrix}\n",
    "$$\n",
    "\n",
    "Let us define a new partitioning grid with the step value of $ r \\cdot h $ and then calculate the value of a target function $ z $ on the grid:\n",
    "\n",
    "$$\n",
    "\\begin{matrix}\n",
    "z \\approx \\zeta(r \\cdot h) + r^p \\cdot O(h^p) & (12)\n",
    "\\end{matrix}\n",
    "$$\n",
    "\n",
    "By combining two partition grids from (11) and (12), we rearrange terms and discard the main term of the precision order $ O(h^p) $ and get an estimation of the target function value $ z $ with the higher precision order:\n",
    "\n",
    "$$\n",
    "\\begin{matrix}\n",
    "z \\approx \\frac{r^p \\zeta(h) - \\zeta(r \\cdot h)}{r^p - 1} + O(h^{p+1}) & (13)\n",
    "\\end{matrix}\n",
    "$$\n",
    "\n",
    "Now if we can derive an estimation for the definition in (11) by extracting from it the equation (13):\n",
    "\n",
    "$$\n",
    "\\begin{matrix}\n",
    "O(h^p) \\approx \\frac{\\zeta(h) - \\zeta(r \\cdot h)}{r^p - 1} & (14)\n",
    "\\end{matrix}\n",
    "$$\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;By applying the estimations (13) - (14) we get the finite-difference approximation equations for left-side, central and right-side derivatives with the precision order $ O(h^2) $:\n",
    "\n",
    "$$\n",
    "\\begin{matrix}\n",
    "\\begin{cases} f'(x) = \\frac{-3f(x) + 4f(x + h) - f(x + 2h)}{2h} + \\frac{h^{2} f'''(\\xi)}{3} \\\\ f'(x) = \\frac{f(x + h) - f(x - h)}{2h} + \\frac{h^{2} f'''(\\xi)}{6} \\\\ f'(x) = \\frac{f(x - 2h) - 4f(x - h) + 3f(x)}{2h} + \\frac{h^{2} f'''(\\xi)}{3} \\end{cases} & (15)\n",
    "\\end{matrix}\n",
    "$$\n",
    "\n",
    "The approach of approximating the gradient value of the target function with a finite-difference schema lets us generalize optimization problems on any kind of analytical functions. Therefore, the convergence of the modern gradient descent algorithms is theoretically proven only for convex and smooth function types. We propose a modification to the existing gradient methods using finite-difference schema that is robust to the non-convex and non-smooth functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7af3a186",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hlgrad(F: Callable[[np.array], np.array], x: np.array, h=0.001) -> np.array:\n",
    "    \"\"\"A finite-difference approximation for left-side gradient $\\nabla F_{-}(x)$ with the higher precision order $O(h^2)$.\n",
    "    Args:\n",
    "        F (Callable[[np.array], np.array]): a target function $F(x)$ with a single input argument $x \\in \\mathbb{R}^n$.\n",
    "        x (np.array): an input vector $x \\in \\mathbb{R}^n$, where the derivative is calculated.\n",
    "        h (float, optional): a step of the derivative partitioning grid with the range of $0<h<1$. The lower value, the higher gradient precision. Defaults to 0.001.\n",
    "    Returns:\n",
    "        np.array: a gradient vector approximation $\\nabla F_{-}(x)$.\n",
    "    \"\"\"\n",
    "    \n",
    "    n, grad = len(x), np.zeros(x.shape)\n",
    "\n",
    "    for i in range(n):\n",
    "        vh = h * np.eye(1, n, i).reshape((n, ))\n",
    "        grad[i] = (-3.0 * F(x) + 4.0 * F(x + vh) - F(x + 2.0 * vh)) / (2.0 * h)\n",
    "\n",
    "    return grad\n",
    "\n",
    "\n",
    "def hcgrad(F: Callable[[np.array], np.array], x: np.array, h=0.001) -> np.array:\n",
    "    \"\"\"A finite-difference approximation for central gradient $\\nabla F(x)$ with the higher precision order $O(h^2)$.\n",
    "    Args:\n",
    "        F (Callable[[np.array], np.array]): a target function $F(x)$ with a single input argument $x \\in \\mathbb{R}^n$.\n",
    "        x (np.array): an input vector $x \\in \\mathbb{R}^n$, where the derivative is calculated.\n",
    "        h (float, optional): a step of the derivative partitioning grid with the range of $0<h<1$. The lower value, the higher gradient precision. Defaults to 0.001.\n",
    "    Returns:\n",
    "        np.array: a gradient vector approximation $\\nabla F(x)$.\n",
    "    \"\"\"\n",
    "\n",
    "    n, grad = len(x), np.zeros(x.shape)\n",
    "    \n",
    "    for i in range(n):\n",
    "        vh = h * np.eye(1, n, i).reshape((n, ))\n",
    "        grad[i] = (F(x + vh) - F(x - vh)) / (2.0 * h)\n",
    "    \n",
    "    return grad\n",
    "\n",
    "\n",
    "def hrgrad(F: Callable[[np.array], np.array], x: np.array, h=0.001) -> np.array:\n",
    "    \"\"\"A finite-difference approximation for right-side gradient $\\nabla F_{+}(x)$ with the higher precision order $O(h^2)$.\n",
    "    Args:\n",
    "        F (Callable[[np.array], np.array]): a target function $F(x)$ with a single input argument $x \\in \\mathbb{R}^n$.\n",
    "        x (np.array): an input vector $x \\in \\mathbb{R}^n$, where the derivative is calculated.\n",
    "        h (float, optional): a step of the derivative partitioning grid with the range of $0<h<1$. The lower value, the higher gradient precision. Defaults to 0.001.\n",
    "    Returns:\n",
    "        np.array: a gradient vector approximation $\\nabla F_{+}(x)$.\n",
    "    \"\"\"\n",
    "\n",
    "    n, grad = len(x), np.zeros(x.shape)\n",
    "\n",
    "    for i in range(n):\n",
    "        vh = h * np.eye(1, n, i).reshape((n, ))\n",
    "        grad[i] = (F(x - 2.0 * vh) - 4.0 * F(x - vh) + 3.0 * F(x)) / (2.0 * h)\n",
    "\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16088e96",
   "metadata": {},
   "source": [
    "Let us experimentally evaluate the accuracy of the higher order gradient on the same test functions set. We get the same accuracy order for a smaller step size $ h $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "483c0fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 1e-5\n",
    "x_onedim = np.array([2.0])\n",
    "x_muldim = np.array([2.0, -1.0])\n",
    "\n",
    "f = lambda x: x ** 3 + 2 * x ** 2 + 12 * x + 100\n",
    "F = lambda x: x[0] ** 2 + x[0] * x[1] + x[1] ** 2\n",
    "\n",
    "np.testing.assert_almost_equal(hlgrad(f, x_onedim, h=h), 32.0, decimal=5)\n",
    "np.testing.assert_almost_equal(hcgrad(f, x_onedim, h=h), 32.0, decimal=5)\n",
    "np.testing.assert_almost_equal(hrgrad(f, x_onedim, h=h), 32.0, decimal=5)\n",
    "\n",
    "np.testing.assert_almost_equal(hlgrad(F, x_muldim, h=h), np.array([3.0, 0.0]), decimal=5)\n",
    "np.testing.assert_almost_equal(hcgrad(F, x_muldim, h=h), np.array([3.0, 0.0]), decimal=5)\n",
    "np.testing.assert_almost_equal(hrgrad(F, x_muldim, h=h), np.array([3.0, 0.0]), decimal=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504fd5d7",
   "metadata": {},
   "source": [
    "## Continuous functions smoothing\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;The optimization problem of smooth stochastic programming (1) can be generalized using the algorithm of averaged functions (Steklov smoothing algorithm). The main idea is to approximate an expected value of the stochastic oracle $ F(\\cdot) $ over a certain neighborhood $ B_{h}(x) $ with the radius $ h $ for each element $ x $ of the oracle definition space: $ B_{h}(x) = \\{ y \\in \\mathbb{R}^{n}: || y - x || \\leq h \\} $. Here $ || \\cdot ||_{2} $ is the Euclidean norm in the $ \\mathbb{R}^{n} $ space: $ || x || = \\sqrt{\\sum_{i=1}^{n} x_{i}^{2}} $. So if $ h \\to 0 $ then $ B_{h}(x) \\to x $, where $ \\nu_{n} $ is a volume of a neighborhood. As the result, we get a smoothed version of the target function $ F_{h}(x) $ [5]:\n",
    "\n",
    "$$\n",
    "\\begin{matrix}\n",
    "F_{h}(x) = \\frac{1}{\\nu_{n}} \\int_{B_{h}(x)} F(y) dy & (16)\n",
    "\\end{matrix}\n",
    "$$\n",
    "\n",
    "By applying the gradient to the smoothed function we get a subdifferential set for an element $ x_{0} $, which is a set of numbers $ \\{ c_{i} \\in \\mathbb{R} \\} $ where all elements are satisfying the condition for every $ x \\in I $:\n",
    "\n",
    "$$\n",
    "\\begin{matrix}\n",
    "f(x) - f(x_{0}) \\geq c_{i}(x - x_{0}) & (17)\n",
    "\\end{matrix}\n",
    "$$\n",
    "\n",
    "A subdifferential set for a convex function $ f: I \\to \\mathbb{R} $ is a non-empty closed interval $ [a, b] $, where elements $ a, b $ are single directional limits, which follow the constraint of $ a < b $:\n",
    "\n",
    "$$\n",
    "\\begin{matrix}\n",
    "a = \\lim _{x\\to x_{0}^{-}}{\\frac {f(x)-f(x_{0})}{x-x_{0}}} & b = \\lim _{x\\to x_{0}^{+}}{\\frac {f(x)-f(x_{0})}{x-x_{0}}} & (18)\n",
    "\\end{matrix}\n",
    "$$\n",
    "\n",
    "A subdifferential set is a general form of a classic differential and gradient of a target function, as it expands the definition (4) on any type of analytic functions, which also has a corresponding form for the multidimensional functions:\n",
    "\n",
    "$$\n",
    "\\begin{matrix}\n",
    "\\partial f(x_{0})=\\{c \\in \\mathbb {R} ^{n}: f(x)-f(x_{0})\\geq c^{T}(x-x_{0})\\quad \\forall x\\in \\mathbb {R} ^{n}\\} & (19)\n",
    "\\end{matrix}\n",
    "$$\n",
    "\n",
    "If a subdifferential set $ \\{ c_{i} \\} $ for an element $ x_{0} $ contains only a single element, the function is differentiable at this element, therefore this element is a derivative value. Note, that if a $ 0 $ element is included in the subdifferential set, then the $ x_{0} $ is a global minimum of the target function $ f: I \\to \\mathbb{R} $. If a function $ F(\\cdot) $ is a Lipschitz continuity, then it transforms elements from $ (X, \\rho_{X}) $ to the space $ (Y, \\rho_{Y}) $ and there exists a positive constant $ L > 0 $, that satisfies the following conditions:\n",
    "\n",
    "$$\n",
    "\\begin{matrix}\n",
    "\\forall x, y \\in X: \\rho_{Y}(f(x), f(y)) \\leq L \\cdot \\rho_{X}(x, y) & (20)\n",
    "\\end{matrix}\n",
    "$$\n",
    "\n",
    "In other words, the ratio of . A Lipschitz continuity $ F(\\cdot) $ is differentiable, its subdifferential set $ \\partial F(\\cdot) $ equals an expected value of differentiated stochastic oracle [6]:\n",
    "\n",
    "$$\n",
    "\\begin{matrix}\n",
    "\\nabla F_{h}(x) = \\frac{1}{\\nu_{n}} \\int_{B_{h}(x)} \\partial F(y) dy & (21)\n",
    "\\end{matrix}\n",
    "$$\n",
    "\n",
    "Thus the gradient value of a smoothed function $ F_{h}(x) $, if we assume that function $ F(x) $ is continuous, can be approximated by surface integrals:\n",
    "\n",
    "$$\n",
    "\\begin{matrix}\n",
    "\\nabla F_{h}(x) = \\frac{1}{s_{h}} \\int_{S_{h}(x)} F(x + y) N(y) dS = \\frac{1}{h} \\int_{S_{h}(x)} (F(x + y) - F(x)) N(y) dS = \\frac{1}{2h} \\int_{S_{h}(x)} (F(x + y) - F(x - y)) N(y) dS & (22)\n",
    "\\end{matrix}\n",
    "$$\n",
    "\n",
    "where $ s_{h} $ is an area of a sphere surface $ S_{h}(x) $, and $ N(y) $ is an outer normal vector to the surface $ S_{h}(x) $ for a specific element $ y \\in S_{h}(x) $. We can interpret the definition of (22) as a substitution of an analytical differential $ \\partial F(\\cdot) $ with the finite-difference approximation along the normal vector $ N(y) $. It allows us to calculate the gradient value of the stochastic oracle even if it is a non-smooth or a non-convex function. Now the surface integral of a Lipschitz continuity $ F(\\cdot) $ does not guarantee an analytical form of the equation. However, we can get an approximate value of this integral using the Monte-Carlo algorithm. Suppose we define a set of $ K $ uniformly distributed stochastic vectors $ \\tilde{y} $ on an single sphere $ S_{1}(0) = \\{ y \\in \\mathbb{R}^{n}: || y || = 1 \\} $. In that case, we can express the gradient value $ \\nabla F_{h}(x) $ as an expected value in the form of a finite-difference sum along the stochastic vectors:\n",
    "\n",
    "$$\n",
    "\\begin{matrix}\n",
    "\\nabla F_{h}(x) = \\frac{n}{h} \\mathbb{E}_{\\tilde{y}}(F(x + h \\tilde{y}) - F(x)) \\tilde{y} = \\frac{n}{2h} \\mathbb{E}_{\\tilde{y}}(F(x + h \\tilde{y}) - F(x - h \\tilde{y})) \\tilde{y} = \\mathbb{E}_{\\tilde{y}} || \\frac{1}{2h}  (F(x + h \\tilde{y}) - F(x - h \\tilde{y})) \\tilde{y} ||^{2} \\leq L^{2} & (23)\n",
    "\\end{matrix}\n",
    "$$\n",
    "\n",
    "A Lipschitz continuity $ F(\\cdot) $, by definition, means the rate of change of a function with respect to an independent variable will be not greater than a positive constant $ L > 0 $ (Lipschitz constant) for every element $ x $ of a continuity definition space. Thus the gradient value of a smoothed function, which also describes the rate of change, will be also constrained by the Lipschitz constant, we showed in the expression (23). Based on the generalization (16)-(23), we make algorithms for a stochastic optimization problem robust to the non-smooth and non-convex functions theoretically, which is the key benefit of a proposed research.\n",
    "\n",
    "## Finite-difference algorithm definition\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;Let us define an uniform probability distribution $ \\mu(x) $ on a space $ \\mathbb{R}^{n} $, which has the properties $ \\mu(x) \\geq 0 $ and $ \\int_{\\mathbb{R}^{n}} \\mu(x) dx = 1 $. For a continuous function $ F(x) $, we apply a smooth stochastic approximation (1), similar to the (16), over a neighborhood $ B_{h}(x) = \\mathbb{R}^{n} $ and get a smoothed approximation $ F_{h}(x) $ with the smoothing variable $ h > 0 $, which also represents a size of a smoothing interval:\n",
    "\n",
    "$$\n",
    "\\begin{matrix}\n",
    "F_{h}(x) = \\frac{1}{h^{n}} \\int_{\\mathbb{R}^n} F(x + y) \\mu (\\frac{y}{h}) dy = \\int_{\\mathbb{R}^n} F(x + hz) \\mu (z) dz = \\frac{1}{h^{n}} \\int_{\\mathbb{R}^n} F(y) \\mu (\\frac{y - x}{h}) dy & (24)\n",
    "\\end{matrix}\n",
    "$$\n",
    "\n",
    "Note, that if a function is a Lipschitz continuity, it is also a differentiable function (because the change rate of function over the argument is always finite), thus the gradient of the function $ \\nabla F_{h}(x) $ can be described by the substitution of the expression inside the integral in (24):\n",
    "\n",
    "$$\n",
    "\\begin{matrix}\n",
    "\\nabla F_{h}(x) = \\frac{1}{h^{n}} \\int_{\\mathbb{R}^n} \\partial F(x + y) \\mu (\\frac{y}{h}) dy = \\int_{\\mathbb{R}^n} \\partial F(x + hz) \\mu (z) dz & (25)\n",
    "\\end{matrix}\n",
    "$$\n",
    "\n",
    "Let us define a certain neighborhood $ B_{h}(x) $ with the radius $ h $ for an element $ x $, which has a property $ \\lim_{h \\to 0} B_{h}(x) = x $. By applying the Steklov algorithm (16), we get a smoothed version of the target function. Then similarly to the (22) we get a subgradient value of a smoothed target function by calculating a surface integral of the sphere area $ S_{h}(x) $. If we define the neighborhood $ B_{h}(x) $ not in the form of a hypersphere $ B_{h}(x) = \\{ y \\in \\mathbb{R}^{n}: || y - x || \\leq h \\} $, but rather using a metric $ p_{\\infty} $, we get the hypercube-like neighborhood:\n",
    "\n",
    "$$\n",
    "\\begin{matrix}\n",
    "B_{h}(x) = \\{ y = (y_{1}, ..., y_{n}) \\in \\mathbb{R}^{n}: \\max_{1 \\leq i \\leq n} | y_{i} - x_{i} | \\leq h \\} & (26)\n",
    "\\end{matrix}\n",
    "$$\n",
    "\n",
    "The smoothing over a hypercube simplifies the Steklov algorithm down to the integrating over the series of the hypercube edges:\n",
    "\n",
    "$$\n",
    "\\begin{matrix}\n",
    "F_{h}(x) = \\frac{1}{h^{n}} \\int_{x_{1} - \\frac{h}{2}}^{x_{1} + \\frac{h}{2}} ... \\int_{x_{n} - \\frac{h}{2}}^{x_{n} + \\frac{h}{2}} F(y) dy_{1} ... dy_{n} & (27)\n",
    "\\end{matrix}\n",
    "$$\n",
    "\n",
    "By applying the approximation of the subdifferential into a set of finite-differences to the expression (27), similarly to the (22)-(23), we get an expected value for every element  in a Lipschitz continuity:\n",
    "\n",
    "$$\n",
    "\\begin{matrix}\n",
    "\\frac{\\partial F_{h}(x)}{\\partial x_{i}} = \\frac{1}{h^{n-1}} \\int_{x_{1} - \\frac{h}{2}}^{x_{1} + \\frac{h}{2}} ... \\int_{x_{i-1} - \\frac{h}{2}}^{x_{i-1} + \\frac{h}{2}} \\int_{x_{i+1} - \\frac{h}{2}}^{x_{i+1} + \\frac{h}{2}} ... \\int_{x_{n} - \\frac{h}{2}}^{x_{n} + \\frac{h}{2}} \\Delta_{h}(x) dy_{1} ... dy_{i-1} dy_{i+1} dy_{n} & (28)\n",
    "\\end{matrix}\n",
    "$$\n",
    "\n",
    "where a smoothing finite-difference under the integral $ \\Delta_{h}(y) = h^{-1} (F(y_{1}, ..., y_{i-1}, x_{i} + \\frac{h}{2}, y_{i+1}, ..., y_{n}) - F(y_{1}, ..., y_{i-1}, x_{i} - \\frac{h}{2}, y_{i+1}, ..., y_{n})) $ has a step size of $ h $. Now by applying the Monte-Carlo transformation from (23) we get the finite-difference sum along the stochastic vectors, which by definition is also constrained by a Lipschitz constant. The gradient descent element sequence is defined by the recurrent rule:\n",
    "\n",
    "$$\n",
    "\\begin{matrix}\n",
    "x^{k} = x^{k-1} - \\lambda \\cdot \\nabla f(x^{k-1}) & (29)\n",
    "\\end{matrix}\n",
    "$$\n",
    "\n",
    "To improve the convergence for non-convex and non-smooth functions we can substitute the gradient value with the finite-difference approximation.\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;Consider a Lipschitz continuity $ F(x) $ defined on a sphere $ \\{ x \\in \\mathbb{R}^{n}: || x || \\leq r \\} $ with a subgradient set $ \\partial F(x) $ and all continuity definition space $ X^{*} = \\{ x: ||x|| \\leq r, 0 \\in \\partial F(x) \\} $ is finite. The definition space contains the element of a global minima $ \\bar{x_{0}} $, $ \\bar{x_{0}} < r $, that satisfies the conditions $ F(\\bar{x_{0}}) < \\min_{|| x || = r} F(x) $. We define a convergence sequence by the rule:\n",
    "\n",
    "$$\n",
    "\\begin{matrix}\n",
    "x_{k+1} = \\begin{cases} x_{k} - \\lambda_{k} \\eta_{k}, & || x_{k} || \\leq r, \\\\ x_{0}, & || x_{k} || > r \\end{cases}, x_{0} = \\bar{x_{0}}, k = 0, 1, ... & (30)\n",
    "\\end{matrix}\n",
    "$$\n",
    "\n",
    "where $ \\eta_{k} = \\frac{1}{2h_{k}} (F(x_{k} + h_{k} \\tilde{y_{k}}) - F(x_{k} - h_{k} \\tilde{y_{k}})) $ - a stochastic finite-difference with the upper limit of $ L^{2} $ along uniformly distributes the stochastic vectors $ \\{ \\tilde{y_{k}} \\} $ on an sphere $ S_{h}(x) $ radius one with the center at a zero-element. Then all limit points of a stochastic sequence $ \\{ x_{k} \\} $ belong to the definition space $ X^{*} = \\{ x: ||x|| \\leq r, 0 \\in \\partial F(x) \\} $ and the numerical sequence $ \\{ F(x_{k}) \\} $ has a limit, if a gradient descent step $ \\lambda $ and a smoothing parameter $ h_{k} $ converge to a specific element:\n",
    "\n",
    "$$\n",
    "\\begin{matrix}\n",
    "\\begin{matrix}\n",
    "\\lambda_{k} > 0, h_{k} \\geq h_{k+1} > 0 \\\\\n",
    "\\lim_{k \\to \\infty} h_{k} = \\lim_{k \\to \\infty} \\frac{\\lambda_{k}}{h_{k}} = \\lim_{k \\to \\infty} \\frac{h_{k} - h_{k + 1}}{\\lambda_{k}} = 0 \\\\\n",
    "\\sum_{k=0}^{\\infty} \\lambda_{k}^{2} < \\infty, \\sum_{k=0}^{\\infty} \\lambda_{k} = + \\infty\n",
    "\\end{matrix} & (31)\n",
    "\\end{matrix}\n",
    "$$\n",
    "\n",
    "Conclusions at (30)-(31) give us an analytical proof for algorithm convergence for any Lipschitz continuity, even if it is non-convex and non-smooth.\n",
    "\n",
    "${}$\n",
    "\n",
    "***\n",
    "\n",
    "**Algorithm 1**  Finite-difference gradient descent\n",
    "\n",
    "***\n",
    "\n",
    "**Require:** $ F(x) $ any Lipschitz continuity, $ x_{0} $ a start element of a sequence, $ 0 < \\lambda < 1 $ a gradient descent step, $ \\varepsilon_{1}, \\varepsilon_{2} $ accuracy parameters, $ K $ a number of finite-differences per step, $ h_{i} $ smoothing parameters\n",
    " 1. $ i = 0 $\n",
    " 2. **while** $ | x^{(i)} - x^{(i-1)} | \\geq \\varepsilon_{1} $ **and** $ | F_{h}(x^{(i)}) - F_{h}(x^{(i-1)}) | \\geq \\varepsilon_{2} $\n",
    " 3. &nbsp;&nbsp;&nbsp;&nbsp;**for** $ k = 1...K $ **do**\n",
    " 4. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$ \\tilde{y_{k, i}} \\sim U(S_{h}(x)) $\n",
    " 5. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$ \\Delta_{k}(x^{(i)}) = \\frac{1}{2h_{i}} (F(x^{(i)} + h_{i} \\tilde{y_{k, i}}) - F(x^{(i)} - h_{i} \\tilde{y_{k, i}}))\\tilde{y_{k, i}} $\n",
    " 6. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$ \\Delta(x^{(i)}) = \\Delta(x^{(i)}) + \\Delta_{k}(x^{(i)}) $\n",
    " 7. &nbsp;&nbsp;&nbsp;&nbsp;**end for**\n",
    " 8. &nbsp;&nbsp;&nbsp;&nbsp;$ \\eta_{i} = \\frac{1}{K} \\Delta(x^{(i)}) \\tilde{y_{k, i}} $\n",
    " 9. &nbsp;&nbsp;&nbsp;&nbsp;$ x^{i+1} = x^{i} - \\lambda \\cdot \\eta_{i} $\n",
    " 10. &nbsp;&nbsp;&nbsp;&nbsp;$ i = i + 1 $\n",
    " 11. **end while**\n",
    " 12. return $ x^{i} $\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf22b9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hsmgrad(F: Callable[[np.array], np.array], x: np.array, h=0.001, k=10) -> np.array:\n",
    "    \"\"\"A smoothed finite-difference approximation for gradient $\\nabla F_{h}(x)$ with the higher precision order $O(h^2)$. \n",
    "Can be also applied to the non-smooth and (or) non-convex target function.\n",
    "    Args:\n",
    "        F (Callable[[np.array], np.array]): a target function $F(x)$ with a single input argument $x \\in \\mathbb{R}^n$. \n",
    "        x (np.array): an input vector $x \\in \\mathbb{R}^n$, where the derivative is calculated.\n",
    "        h (float, optional): a step of the derivative partitioning grid with the range of $0<h<1$. The lower value, the higher gradient precision. Defaults to 0.001.\n",
    "        k (int, optional): a order of smoothing $k \\in \\mathbb{N}$. The higher value, the higher gradient precision. Defaults to 10.\n",
    "    Returns:\n",
    "        np.array: a gradient vector approximation $\\nabla F_{h}(x)$.\n",
    "    \"\"\"\n",
    "\n",
    "    n, grad = len(x), np.zeros(x.shape)\n",
    "\n",
    "    for _ in range(k):\n",
    "        grad_component = np.zeros(x.shape)\n",
    "        yi_dir = np.random.uniform(0.0, 1.0, (1, n)).reshape((n, ))\n",
    "        yi = yi_dir / np.linalg.norm(yi_dir)\n",
    "\n",
    "        for j in range(n):\n",
    "            vh = h * np.eye(1, n, j).reshape((n, ))\n",
    "            grad_component[j] = (F(x + vh * yi) - F(x - vh * yi)) / (2.0 * h)\n",
    "\n",
    "        grad += grad_component\n",
    "\n",
    "    return grad / k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36a801a",
   "metadata": {},
   "source": [
    "Let us compare the values of a smoothed gradient and a regular gradient on a test function set. Because the smoothed gradient is an averaged composition of gradient values in a random direction, the final value may differ significantly from the regular gradient value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6055d46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "| k | f(x) | F(x) |\n",
       "| --- | --- | --- |\n",
       "| 0 | 32.0 | [3. 0.] |\n",
       "| 3 | 32.0 | [0.8 0. ] |\n",
       "| 5 | 32.0 | [ 1.495 -0.   ] |\n",
       "| 10 | 32.0 | [ 1.479 -0.   ] |\n",
       "| 20 | 32.0 | [ 2.23 -0.  ] |\n",
       "| 100 | 32.0 | [ 2.095 -0.   ] |\n",
       "| 500 | 32.0 | [ 1.949 -0.   ] |\n",
       "| 1000 | 32.0 | [1.93 0.  ] |\n",
       "| 5000 | 32.0 | [ 1.956 -0.   ] |\n",
       "| 100000 | 32.0 | [1.944 0.   ] |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown, Latex\n",
    "\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "h = 1e-5\n",
    "k = [0, 3, 5, 10, 20, 100, 500, 1000, 5000, 100000]\n",
    "x_onedim = np.array([2.0])\n",
    "x_muldim = np.array([2.0, -1.0])\n",
    "\n",
    "f = lambda x: x ** 3 + 2 * x ** 2 + 12 * x + 100\n",
    "F = lambda x: x[0] ** 2 + x[0] * x[1] + x[1] ** 2\n",
    "\n",
    "grads_onedim = { ki: hcgrad(f, x_onedim, h=h) if ki == 0 else hsmgrad(f, x_onedim, h=h, k=ki) for ki in k }\n",
    "grads_muldim = { ki: hcgrad(F, x_muldim, h=h) if ki == 0 else hsmgrad(F, x_muldim, h=h, k=ki) for ki in k }\n",
    "\n",
    "display(\n",
    "    Markdown('\\n'.join([\n",
    "        '| k | f(x) | F(x) |',\n",
    "        '| --- | --- | --- |',\n",
    "        *[\n",
    "            f'| {ki} | {np.around(grads_onedim[ki], 3).item()} | {np.around(grads_muldim[ki], 3)} |'\n",
    "            for ki in k\n",
    "        ]\n",
    "    ]))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a77ef15",
   "metadata": {},
   "source": [
    "## Convergence speed of an algorithm\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp; As mentioned in the paragraphs above, the critical metrics for the efficiency of the gradient descent method are convergence speed and the existence of upper boundaries of a sequence $ \\{ x_t \\} $, which means that each element of a set belongs to a function definition space. Unlike classic gradient descent algorithms, our modification assures convergence towards the minima with a certain finite speed for any Lipschitz continuity, making it more efficient for most optimization problems.\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp; ***Lemma 1 “A set measure concentration” [7].*** For any Lipschitz continuity $ F $ and any uniform distribution $ \\xi $ on a single sphere $ S_1(0) $ in the $ n $-dimensional Euclidean space the expected difference between any value of distribution and its averaged value always has an upper boundaries:\n",
    "\n",
    "$$\n",
    "\\begin{matrix}\n",
    "\\sqrt{ \\mathbb{E} [(F(\\xi) - \\mathbb{E} [F(\\xi)] )^4] } \\leq C \\cdot \\frac{L^2}{n} & (32)\n",
    "\\end{matrix}\n",
    "$$\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp; ***Theorem 3 “Existence of an upper boundary of a convergence sequence”.*** Given any Lipschitz continuity $ F $ with a Lipschitz constant $ L $ and any subset $ X \\subseteq \\mathbb{R}^n $ constrained by the upper boundary $ || X || = \\sup_{x \\in X} || x || \\leq D $. The convergence sequence $ \\{ x_t \\} $ is defined by the recurrent equation:\n",
    "\n",
    "$$\n",
    "\\begin{matrix}\n",
    "x_{t+1} = \\pi_{x} (x_{t} - \\lambda_{t} \\eta_{t}), t = 1, ..., T & (33)\n",
    "\\end{matrix}\n",
    "$$\n",
    "\n",
    "where $ \\eta_t = \\frac{1}{K} \\sum_{k=1}^K \\frac{1}{2 h_t} (F(x_t + h_t \\tilde{y_t^k}) - F(x_t - h_t \\tilde{y_t^k})) \\tilde{y_t^k} $ - a stochastic finite-difference with the upper limit of $ L^2 $ along uniformly distributes the stochastic vectors $ \\{ \\tilde{y_t^k} \\} $, $ \\pi_{x} $ - a projection operator on the function definition space $ X $, $ T $ - the number of iterations, $ \\lambda_t $ - finite gradient descent steps, $ h_t $ - smoothing parameters. If the step size have a fixed value $ \\lambda = \\frac{D \\sqrt{n}}{L \\sqrt{T}} $, for some constant $ C > 0 $ and an averaged element of a sequence $ \\bar{x_T} = \\frac{1}{T} \\sum_{t=1}^{T} x_t $ we get the upper boundary estimation for an algorithm convergence speed:\n",
    "\n",
    "$$\n",
    "\\begin{matrix}\n",
    "\\begin{cases} \\mathbb{E}[ F_{h}(\\bar{x_{T}}) - \\min_{x \\in X} F_{h}(x) ] \\leq \\frac{1}{2} (1 + C) LD \\sqrt{\\frac{n}{T}}, & h > \\frac{D \\sqrt{n}}{\\sqrt{T}} \\\\ \\mathbb{E}[ F_{h}(\\bar{x_{T}}) - \\min_{x \\in X} F_{h}(x) ] \\leq \\frac{1}{2} (5 + C) LD \\sqrt{\\frac{n}{T}}, &  h \\leq \\frac{D \\sqrt{n}}{\\sqrt{T}} \\end{cases} & (34)\n",
    "\\end{matrix}\n",
    "$$\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp; And if we take the step size with dynamic value $ \\lambda_t = \\frac{D \\sqrt{n}}{L \\sqrt{t}} $ and an averaged element of a sequence $ \\exists t: \\bar{x_t} = \\frac{1}{t} \\sum_{k=1}^{t} x_k $ the upper boundary estimation depends on the iteration number $ t $:\n",
    "\n",
    "$$\n",
    "\\begin{matrix}\n",
    "\\mathbb{E}[ F_{h}(\\bar{x_{T}}) - \\min_{x \\in X} F_{h}(x) ] \\leq \\frac{(1 + C) \\sqrt{n} LD}{2} \\times \\frac{1 + \\ln t}{\\sqrt{t} - 1} & (35)\n",
    "\\end{matrix}\n",
    "$$\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp; In other words, if the step size $ \\lambda_t $ satisfies certain conditions, the distance between the averaged function and the global minima will be always finite and inversely proportional to the iteration number $ t $. Moreover we can get an estimate of this distance on each iteration, which is a measure of an algorithm convergence.\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp; In addition to the Theorem 3 we can approximate the value of an upper boundary without a specific constant $ C > 0 $, but with a number of finite differences per step $ K $. If the step size have a fixed value $ \\lambda = \\frac{D \\sqrt{n K}}{L \\sqrt{T (1 + \\frac{K - 1}{n})}} $, we get the upper boundary estimation:\n",
    "\n",
    "$$\n",
    "\\begin{matrix}\n",
    "\\mathbb{E}[ F_{h}(\\bar{x_{T}}) - \\min_{x \\in X} F_{h}(x) ] \\leq \\frac{L D}{\\sqrt{T}} \\sqrt{1 - \\frac{1}{K} + \\frac{n}{K}} \\leq \\frac{L D}{\\sqrt{T}} (1 + \\sqrt{\\frac{n}{K}}) & (36)\n",
    "\\end{matrix}\n",
    "$$\n",
    "\n",
    "This estimation gives us an insight that the efficiency of a proposed algorithm modification depends only on a target function dimensionality $ n $, a Lipschitz constant $ L $, and a number of finite differences per step $ K $.\n",
    "\n",
    "## Overview of the existing stochastic gradient descent algorithms\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp; Previously we defined the gradient descent element sequence by the recurrent rule [8]:\n",
    "\n",
    "$$\n",
    "\\begin{matrix}\n",
    "x^k = x^{k-1} + \\beta_{k} \\cdot u^{k}, k \\in \\mathbb{N} & (37)\n",
    "\\end{matrix}\n",
    "$$\n",
    "\n",
    "where $ \\beta_{k} $ - a sequence step, $ u^{k} $ - a direction vector. We also concluded that the anti-gradient vector points to the steepest paths towards the minima elements. If direction vector and an anti-gradient have same direction, then norm of a gradient is equivalent to a scalar dot product between gradient and direction vector:\n",
    "\n",
    "$$\n",
    "\\begin{matrix}\n",
    "\\cos_{-\\nabla f(x^{k-1}), u^{k}} = \\frac{(-\\nabla f(x^{k-1}), u^{k})}{ | -\\nabla f(x^{k-1}) | } = - \\frac{(\\nabla f(x^{k-1}), u^{k})}{ | \\nabla f(x^{k-1}) | } = 1 & (38)\n",
    "\\end{matrix}\n",
    "$$\n",
    "\n",
    "In other words, a direction vector is collinear to the anti-gradient, which we can get by rearranging terms in (38) and norming the gradient vector:\n",
    "\n",
    "$$\n",
    "\\begin{matrix}\n",
    "u^{k} = \\frac{\\nabla f(x^{k-1})}{| \\nabla f(x^{k-1}) |} & (39)\n",
    "\\end{matrix}\n",
    "$$\n",
    "\n",
    "By combining the primary recurrent rule (37) and vector normalization (39), we get a recurrent rule for a *Batch Gradient Descent (BGD)*:\n",
    "\n",
    "$$\n",
    "\\begin{matrix}\n",
    "x^{k} = x^{k-1} - \\beta_{k} \\cdot \\frac{\\nabla f(x^{k-1})}{| \\nabla f(x^{k-1}) |} & (40)\n",
    "\\end{matrix}\n",
    "$$\n",
    "\n",
    "In case a gradient descent step is proportional to the value of an anti-gradient vector, we can simplify a definition (40) by making a substitution $ \\lambda = \\frac{\\beta_{k}}{| \\nabla f(x^{k-1}) |} $:\n",
    "\n",
    "$$\n",
    "\\begin{matrix}\n",
    "x^{k} = x^{k-1} - \\lambda \\cdot \\nabla f(x^{k-1}) & (41)\n",
    "\\end{matrix}\n",
    "$$\n",
    "\n",
    "The equation (41) describes optimization problems for target function minimization. We can also consider a stochastic regression problem, where we search for an optimal independent parameters set $ \\theta $. In that case the target function also depends on a set of input features $ \\{ x_{i, j} \\}_n^m $ and empirical approximation of the output features $ \\{ y_i \\}_n $:\n",
    "\n",
    "$$\n",
    "\\begin{matrix}\n",
    "\\theta^{(i+1)} = \\theta^{(i)} - \\lambda \\nabla_{\\theta} J(\\theta, x, y) & (42)\n",
    "\\end{matrix}\n",
    "$$\n",
    "\n",
    "Note that the Batch Gradient Descent belongs to a “greedy algorithm” category in terms of memory consumption, because it requires loading a whole input feature set into memory.\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp; To fix the issue with non optimal memory consumption, we introduce a stochastic approximation (1) for a recurrent sequence (42), which means that instead of calculating gradient for the whole set of input features $ \\{ x_{i, j} \\}_n^m $ we calculate gradient only for a single element $ x_{i, j} $ per iteration:\n",
    "\n",
    "$$\n",
    "\\begin{matrix}\n",
    "\\theta^{(i+1)} = \\theta^{(i)} - \\lambda \\nabla_{\\theta} \\hat{J} (\\theta_{1...n}^{(i)}, x_{1...n}^{(j)}, y^{(j)}), j = i \\mod n & (43)\n",
    "\\end{matrix}\n",
    "$$\n",
    "\n",
    "The recurrent equation (43) represents a *Stochastic Gradient Descent (SGD)* algorithm. If we consider a condition (3) is not true for a set of input features $ \\{ x_{i, j} \\}_n^m $, then the value of a gradient $ \\nabla_{\\theta} \\hat{J} $ will oscillate within the range of variance of a set $ \\mathbb{V}[ x_{i, j} ] $. Although this feature makes an algorithm more robust to the local minima, the convergence of an algorithm becomes extremely unstable.\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp; To reach a compromise between optimal memory usage and convergence stability, we can apply a stochastic approximation (1) for a recurrent sequence (42) not the whole set of input features $ \\{ x_{i, j} \\}_n^m $, but rather for a randomly selected subset $ M(x_{i, n}) \\subset \\{ x_{i, j} \\}_n^m $ with a fixed size per each step $ \\forall i: |M(x_i)| = m = const $. With these modifications we get a *Mini-Batch Gradient Descent (MGD)* algorithm, a “golden ratio” between BGD and SGD:\n",
    "\n",
    "$$\n",
    "\\begin{matrix}\n",
    "\\theta^{(i + 1)} = \\theta^{(i)} - \\lambda \\nabla_{\\theta} \\hat{J}_{M} (\\theta_{1...n}^{(i)}, x_{1...n}^{(j, j+m)}, y^{(j, j+m)}), j = i \\mod \\frac{n}{m} & (44)\n",
    "\\end{matrix}\n",
    "$$\n",
    "\n",
    "These algorithms still have low convergence speed and are not robust for “noisy” target functions. Also they show a poor performance on a sparse set of input features due to a fixed gradient step value $ \\lambda $. Following implementations of the gradient descent algorithms consider these stop criterias:\n",
    " - \"args\" - norm of difference between adjacent element: $|| x^{i} - x^{i-1} || < \\varepsilon_{1};$\n",
    " - \"func\" - norm of difference between fucntions value of adjacent element: $|| F(x^{i}) - F(x^{i-1}) || < \\varepsilon_{2};$\n",
    " - \"mixed\" - combined criterias of \"args\" and \"func\": $|| x^{i} - x^{i-1} || < \\varepsilon_{1}, || F_{h}(x^{i}) - F_{h}(x^{i-1}) || < \\varepsilon_{2};$\n",
    " - \"grad\" - norm of a gradient value in the current element: $|| \\nabla F(x^{i}) || < \\varepsilon_{1}.$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ff549e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SGD(F: Callable[[np.array], np.array], x: np.array, epoch: int,\n",
    "        step=0.001, eps1=0.001, eps2=0.01, h=0.0001, k=0, criteria=\"grad\") -> Tuple[np.array, np.array, int]:\n",
    "    \"\"\"A Stochastic Gradient Descent (SGD) algorithm.\n",
    "\n",
    "    Args:\n",
    "        F (Callable[[np.array], np.array]): a target function $F(x)$ with a single input argument $x \\in \\mathbb{R}^n$.\n",
    "        x (np.array): a start element $x_0$ in a sequence.\n",
    "        epoch (int): a maximum number of iterations.\n",
    "        step (float, optional): a gradient descent step with the valid range of $0< \\lambda <1$. Defaults to 0.001.\n",
    "        eps1 (float, optional): an argumental accuracy parameter. Defaults to 0.001.\n",
    "        eps2 (float, optional): a functional accuracy parameter. Defaults to 0.01.\n",
    "        h (float, optional): a step of the derivative partitioning grid with the range of $0<h<1$. The lower value, the higher gradient precision. Defaults to 0.001.\n",
    "        k (int, optional): a order of smoothing $k \\in \\mathbb{N}$. The higher value, the higher gradient precision. If equals 0, no smoothing is applied. Defaults to 0.\n",
    "        criteria (str, optional): an early stopping criteria. Defaults to \"grad\".\n",
    "\n",
    "    Returns:\n",
    "        Tuple[np.array, np.array, int]: An optimal vector, a gradient descent sequence, and a number of iterations.\n",
    "    \"\"\"\n",
    "\n",
    "    xi, it = np.copy(x), 0\n",
    "\n",
    "    for _ in range(epoch):\n",
    "        grad = hcgrad(F, x, h) if k == 0 else hsmgrad(F, x, h, k)\n",
    "        x = x - step * grad\n",
    "        xi = np.vstack((xi, x))\n",
    "\n",
    "        if criteria == \"args\" and np.linalg.norm(xi[-1] - xi[-2]) < eps1: break\n",
    "        elif criteria == \"func\" and np.linalg.norm(F(xi[-1]) - F(xi[-2])) < eps2: break\n",
    "        elif criteria == \"mixed\" and (np.linalg.norm(xi[-1] - xi[-2]) < eps1 and np.linalg.norm(F(xi[-1]) - F(xi[-2])) < eps2): break\n",
    "        elif criteria == \"grad\" and np.linalg.norm(grad) < eps1: break\n",
    "        else: it += 1\n",
    "\n",
    "    return x, xi, it"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
